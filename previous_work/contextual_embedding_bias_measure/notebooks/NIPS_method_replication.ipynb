{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from bert_utils import Config, BertPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    model_type=\"bert-base-uncased\",\n",
    "    max_seq_len=128,\n",
    "    subspace_size=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = BertPreprocessor(config.model_type, config.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): BertLayerNorm()\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_pretrained_bert import BertConfig, BertForMaskedLM\n",
    "model = BertForMaskedLM.from_pretrained(config.model_type)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ContextWord:\n",
    "    sent: str\n",
    "    word: str\n",
    "    def __post_init__(self):\n",
    "        assert self.word in self.sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vector(cword: ContextWord, use_last_mask=False):\n",
    "    sentence, word = cword.sent, cword.word\n",
    "    idx = processor.get_index(sentence, word, last=use_last_mask)\n",
    "    outputs = None\n",
    "    with torch.no_grad():\n",
    "        sequence_output, _ = model.bert(processor.to_bert_model_input(sentence),\n",
    "                                        output_all_encoded_layers=False)\n",
    "        sequence_output.squeeze_(0)\n",
    "        if outputs is None: outputs = torch.zeros_like(sequence_output)\n",
    "        outputs = sequence_output + outputs\n",
    "    return outputs.detach().cpu().numpy()[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_sim_matrix(vecs):\n",
    "    sim_matrix = np.zeros((len(vecs), len(vecs)))\n",
    "    for i, v in enumerate(vecs):\n",
    "        for j, w in enumerate(vecs):\n",
    "            sim_matrix[i, j] = cosine_similarity(v, w)\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_sim_matrix_df(sentences: List[str],\n",
    "                           words: List[str]):\n",
    "    sim = construct_sim_matrix([get_word_vector(ContextWord(sent, word)) for sent, word in zip(sentences, words)])\n",
    "    return pd.DataFrame(data=sim, index=words, columns=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_diff_similarity(cwords1, cwords2):\n",
    "    cword11, cword12 = cwords1\n",
    "    cword21, cword22 = cwords2\n",
    "    return cosine_similarity(get_word_vector(cword11) - get_word_vector(cword12),\n",
    "                             get_word_vector(cword21) - get_word_vector(cword22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_softmax = model.cls.predictions.decoder.weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_bias = model.cls.predictions.bias.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_logits(wv: np.ndarray) -> np.ndarray:\n",
    "    return model.cls(torch.FloatTensor(wv).unsqueeze(0)).detach().cpu().numpy()[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>programmer</th>\n",
       "      <th>man</th>\n",
       "      <th>woman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>programmer</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.390309</td>\n",
       "      <td>0.413819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>0.390309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0.413819</td>\n",
       "      <td>0.824558</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            programmer       man     woman\n",
       "programmer    1.000000  0.390309  0.413819\n",
       "man           0.390309  1.000000  0.824558\n",
       "woman         0.413819  0.824558  1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "construct_sim_matrix_df([\"That person is a programmer.\", \n",
    "                         \"I am a man.\", \n",
    "                         \"I am a woman.\"],\n",
    "                       [\"programmer\", \"man\", \"woman\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15081199"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"The programmer went to the office.\", \"programmer\"),\n",
    "     ContextWord(\"The nurse went to the office.\", \"nurse\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23052035"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"The doctor went to the office.\", \"doctor\"),\n",
    "     ContextWord(\"The nurse went to the office.\", \"nurse\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31024465"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"he likes sports.\", \"he\"), ContextWord(\"she likes sports.\", \"she\")),\n",
    "    (ContextWord(\"The doctor went to the office.\", \"doctor\"),\n",
    "     ContextWord(\"The nurse went to the office.\", \"nurse\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find gendered direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original gender terms:\n",
    "- she - he \n",
    "- her - his \n",
    "- woman - man\n",
    "- Mary - John\n",
    "- herself - himself\n",
    "- daughter - son\n",
    "- mother - father\n",
    "- gal - guy\n",
    "- girl - boy\n",
    "- female - male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_vecs, female_vecs = [], []\n",
    "def add_word_vecs(s: str, male_w: str, female_w: str):\n",
    "    male_vecs.append(get_word_vector(ContextWord(s.replace(\"XXX\", male_w), male_w)))\n",
    "    female_vecs.append(get_word_vector(ContextWord(s.replace(\"XXX\", female_w), female_w)))\n",
    "\n",
    "for prof in [\"musician\", \"magician\", \"nurse\", \"doctor\", \"teacher\"]:\n",
    "    add_word_vecs(\"XXX is a YYY\".replace(\"YYY\", prof), \"he\", \"she\")\n",
    "    add_word_vecs(\"XXX works as a YYY\".replace(\"YYY\", prof), \"he\", \"she\")\n",
    "\n",
    "for action in [\"talk to\", \"hit\", \"ignore\", \"please\", \"remove\"]:\n",
    "    add_word_vecs(\"please YYY XXX\".replace(\"YYY\", action), \"him\", \"her\")\n",
    "    add_word_vecs(\"don't YYY XXX\".replace(\"YYY\", action), \"him\", \"her\")\n",
    "\n",
    "for thing in [\"food\", \"music\", \"work\", \"running\", \"cooking\"]:\n",
    "    add_word_vecs(\"XXX dislikes YYY\".replace(\"YYY\", thing), \"man\", \"woman\")\n",
    "    add_word_vecs(\"XXX is thinking about YYY\".replace(\"YYY\", thing), \"man\", \"woman\")\n",
    "    \n",
    "for action in [\"running\", \"thinking\", \"working\", \"watching\", \"reading\"]:\n",
    "    add_word_vecs(\"The XXX is YYY\".replace(\"YYY\", action), \"boy\", \"girl\")\n",
    "    add_word_vecs(\"That XXX likes YYY\".replace(\"YYY\", action), \"boy\", \"girl\")\n",
    "    \n",
    "for adj in [\"fat\", \"cute\", \"attractive\", \"smart\", \"strong\"]:\n",
    "    add_word_vecs(\"My XXX is YYY\".replace(\"YYY\", adj), \"boy\", \"girl\")\n",
    "    add_word_vecs(\"Her XXX is not YYY\".replace(\"YYY\", adj), \"boy\", \"girl\")\n",
    "    \n",
    "for thing in [\"cat\", \"dog\", \"person\", \"word\", \"action\"]:\n",
    "    add_word_vecs(\"XXX is YYY\".replace(\"YYY\", adj), \"male\", \"female\")\n",
    "    add_word_vecs(\"XXX is clearly YYY\".replace(\"YYY\", adj), \"male\", \"female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_vecs = np.r_[male_vecs]\n",
    "female_vecs = np.r_[female_vecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def find_subspace(D: np.ndarray) -> PCA:\n",
    "    assert len(D.shape) == 2\n",
    "    pca = PCA(n_components=config.subspace_size)\n",
    "    return pca.fit(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = find_subspace(male_vecs - female_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a284d7550>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=np.arange(pca.n_components), y=pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what it says in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We denote the projection of a vector $ v $ onto $ B $ by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ v_B = \\sum_{j=1}^{k} (v \\cdot b_j) b_j $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each word $ w \\in N $, let $ \\vec{w} $ be re-embedded to\n",
    "$$ \\vec{w} := \\vec{w} - \\vec{w_{B}} / || \\vec{w} - \\vec{w_{B}} || $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mu := \\sum_{w \\in E}w / |E| $$\n",
    "$$ \\nu := \\mu - \\mu_B $$\n",
    "For each $ w \\in E $, \n",
    "$$ \\vec{w} := \\nu + \\sqrt{1 - ||\\nu||^2}\\frac{\\vec{w_B} - \\mu_B}{||\\vec{w_B} - \\mu_B||} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_subspace(X: np.ndarray, subspace: np.ndarray, norm=True) -> np.ndarray:\n",
    "    Xb = ((X @ subspace.T) @ subspace) # projection onto biased subspace\n",
    "    X = (X - Xb) / (np.linalg.norm(X - Xb))\n",
    "    if norm:\n",
    "        mu = X.mean(0)\n",
    "        mub = Xb.mean(0)\n",
    "        nu = mu - mub\n",
    "        return nu + np.sqrt(1 - nu**2) * (Xb - mub) / np.linalg.norm(Xb - mub)\n",
    "    else:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06290086, -0.09486511, -0.02813759, ..., -0.0434248 ,\n",
       "        -0.10185718,  0.06568658],\n",
       "       [-0.06342987, -0.09343787, -0.03166636, ..., -0.04076874,\n",
       "        -0.10113938,  0.06436405],\n",
       "       [-0.06442956, -0.0938312 , -0.0318265 , ..., -0.04132402,\n",
       "        -0.10287223,  0.06333586],\n",
       "       ...,\n",
       "       [-0.06907068, -0.10305111, -0.02295203, ..., -0.05188077,\n",
       "        -0.11271352,  0.0673346 ],\n",
       "       [-0.06983964, -0.10438715, -0.02219164, ..., -0.05312242,\n",
       "        -0.11442181,  0.06829524],\n",
       "       [-0.06907068, -0.10305111, -0.02295203, ..., -0.05188077,\n",
       "        -0.11271352,  0.0673346 ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_subspace(male_vecs, pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newly checking for differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Postprocess\"\"\"\n",
    "    return remove_subspace(np.expand_dims(X, 0), pca.components_, norm=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_new_diff_similarity(cwords1, cwords2):\n",
    "    cword11, cword12 = cwords1\n",
    "    cword21, cword22 = cwords2\n",
    "    return cosine_similarity(pp(get_word_vector(cword11)) - pp(get_word_vector(cword12)),\n",
    "                             pp(get_word_vector(cword21)) - pp(get_word_vector(cword22)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarities are being reduced, so there is a shared gender subspace to a certain extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15081199, 0.12542927)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"The programmer went to the office.\", \"programmer\"),\n",
    "     ContextWord(\"The nurse went to the office.\", \"nurse\"))\n",
    "),\n",
    "compute_new_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"The programmer went to the office.\", \"programmer\"),\n",
    "     ContextWord(\"The nurse went to the office.\", \"nurse\"))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23052035, 0.14701228)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"The doctor went to the office.\", \"doctor\"),\n",
    "     ContextWord(\"The nurse went to the office.\", \"nurse\"))\n",
    "),\n",
    "compute_new_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"The doctor went to the office.\", \"doctor\"),\n",
    "     ContextWord(\"The nurse went to the office.\", \"nurse\"))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.31024465, 0.23461923)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(compute_diff_similarity(\n",
    "    (ContextWord(\"he likes sports.\", \"he\"), ContextWord(\"she likes sports.\", \"she\")),\n",
    "    (ContextWord(\"The doctor went to the office.\", \"doctor\"),\n",
    "     ContextWord(\"The nurse went to the office.\", \"nurse\"))\n",
    "),\n",
    "compute_new_diff_similarity(\n",
    "    (ContextWord(\"he likes sports.\", \"he\"), ContextWord(\"she likes sports.\", \"she\")),\n",
    "    (ContextWord(\"The doctor went to the office.\", \"doctor\"),\n",
    "     ContextWord(\"The nurse went to the office.\", \"nurse\"))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for change in bias score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the bias score decreases with this transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_score(sentence: str, gender_words: Iterable[str], \n",
    "               word: str, gender_comes_first=True, \n",
    "               correct_bias=True,\n",
    "               postprocess=False) -> float:    \n",
    "    mw, fw = gender_words\n",
    "    mwi, fwi = processor.token_to_index(mw), processor.token_to_index(fw)\n",
    "    wv = get_word_vector(\n",
    "        ContextWord(sentence.replace(\"XXX\", word).replace(\"GGG\", \"[MASK]\"), \"[MASK]\"),\n",
    "        use_last_mask=not gender_comes_first,        \n",
    "    )\n",
    "    if postprocess: wv = pp(wv)\n",
    "    logits = to_logits(wv)\n",
    "    subject_fill_bias = logits[mwi] - logits[fwi]\n",
    "    if correct_bias:\n",
    "        wv = get_word_vector(\n",
    "            ContextWord(sentence.replace(\"XXX\", \"[MASK]\").replace(\"GGG\", \"[MASK]\"), \"[MASK]\"),\n",
    "            use_last_mask=gender_comes_first,\n",
    "        )\n",
    "        if postprocess: wv = pp(wv)\n",
    "        prior_logits = to_logits(wv)\n",
    "        prior_bias = prior_logits[mwi] - prior_logits[fwi]\n",
    "        subject_fill_bias = subject_fill_bias - prior_bias\n",
    "    return subject_fill_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias is reduced here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32679677"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is a XXX.\", [\"he\", \"she\"], \"doctor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20236921"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is a XXX.\", [\"he\", \"she\"], \"doctor\", postprocess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias is neutralized here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.859275"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is a XXX.\", [\"he\", \"she\"], \"nurse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5139458"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is a XXX.\", [\"he\", \"she\"], \"nurse\", postprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing for adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.4315097"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is very XXX.\", [\"he\", \"she\"], \"beautiful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6366044"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is very XXX.\", [\"he\", \"she\"], \"beautiful\", postprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4758742"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is very XXX.\", [\"he\", \"she\"], \"dangerous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03879726"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is very XXX.\", [\"he\", \"she\"], \"dangerous\", postprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.32514405"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is very XXX.\", [\"he\", \"she\"], \"cute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12032664"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is very XXX.\", [\"he\", \"she\"], \"cute\", postprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unintended Side Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any unintended side effects of this transformation? Let's test and see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0094642835"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"The programmer went to the office.\", \"programmer\"),\n",
    "     ContextWord(\"The doctor went to the office.\", \"doctor\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    " def construct_sim_matrix_df(cws: List[ContextWord]):\n",
    "    return pd.DataFrame(data=sim, index=words, columns=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>programmer</th>\n",
       "      <th>doctor</th>\n",
       "      <th>nurse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>programmer</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.683078</td>\n",
       "      <td>0.634901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctor</th>\n",
       "      <td>0.683078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.835144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>0.634901</td>\n",
       "      <td>0.835144</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            programmer    doctor     nurse\n",
       "programmer    1.000000  0.683078  0.634901\n",
       "doctor        0.683078  1.000000  0.835144\n",
       "nurse         0.634901  0.835144  1.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cws = [\n",
    "    ContextWord(\"The programmer went to the office.\", \"programmer\"),\n",
    "    ContextWord(\"The doctor went to the office.\", \"doctor\"),\n",
    "    ContextWord(\"The nurse went to the office.\", \"nurse\"),\n",
    "]\n",
    "sim = construct_sim_matrix([get_word_vector(cw) for cw in cws])\n",
    "pd.DataFrame(data=sim, index=[cw.word for cw in cws], columns=[cw.word for cw in cws])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the similarities here seem to be roughly preserved; perhaps because we are neutralizing w.r.t to the gender dimension in the subject space, but not the object space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>programmer</th>\n",
       "      <th>doctor</th>\n",
       "      <th>nurse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>programmer</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.678573</td>\n",
       "      <td>0.630049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctor</th>\n",
       "      <td>0.678573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>0.630049</td>\n",
       "      <td>0.832840</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            programmer    doctor     nurse\n",
       "programmer    1.000000  0.678573  0.630049\n",
       "doctor        0.678573  1.000000  0.832840\n",
       "nurse         0.630049  0.832840  1.000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = construct_sim_matrix([pp(get_word_vector(cw)) for cw in cws])\n",
    "pd.DataFrame(data=sim, index=[cw.word for cw in cws], columns=[cw.word for cw in cws])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beautiful</th>\n",
       "      <th>dangerous</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beautiful</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600859</td>\n",
       "      <td>0.583575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dangerous</th>\n",
       "      <td>0.600859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.536445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>0.583575</td>\n",
       "      <td>0.536445</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           beautiful  dangerous    normal\n",
       "beautiful   1.000000   0.600859  0.583575\n",
       "dangerous   0.600859   1.000000  0.536445\n",
       "normal      0.583575   0.536445  1.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cws = [\n",
    "    ContextWord(\"Your colleague is very beautiful.\", \"beautiful\"),\n",
    "    ContextWord(\"Your colleague is very dangerous.\", \"dangerous\"),\n",
    "    ContextWord(\"Your colleague is very normal.\", \"normal\"),\n",
    "]\n",
    "sim = construct_sim_matrix([get_word_vector(cw) for cw in cws])\n",
    "pd.DataFrame(data=sim, index=[cw.word for cw in cws], columns=[cw.word for cw in cws])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, not much reduction in similarities here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beautiful</th>\n",
       "      <th>dangerous</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beautiful</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601322</td>\n",
       "      <td>0.581689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dangerous</th>\n",
       "      <td>0.601322</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.525321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>0.581689</td>\n",
       "      <td>0.525321</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           beautiful  dangerous    normal\n",
       "beautiful   1.000000   0.601322  0.581689\n",
       "dangerous   0.601322   1.000000  0.525321\n",
       "normal      0.581689   0.525321  1.000000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = construct_sim_matrix([pp(get_word_vector(cw)) for cw in cws])\n",
    "pd.DataFrame(data=sim, index=[cw.word for cw in cws], columns=[cw.word for cw in cws])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linearity of BERT embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT embeddings no longer express the same linear semantics as word2vec/GloVe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57149196"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"I am a king.\", \"king\"),\n",
    "     ContextWord(\"I am a queen.\", \"queen\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4555073"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"he is my friend.\", \"he\"), ContextWord(\"she is my friend.\", \"she\")),\n",
    "    (ContextWord(\"they are the king.\", \"king\"),\n",
    "     ContextWord(\"they are the queen.\", \"queen\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in direction does not stay constant as the subject/object status of the word changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35181317"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"The king walked across the road.\", \"king\"),\n",
    "     ContextWord(\"The queen walked across the road.\", \"queen\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24944247"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"king does not do such things.\", \"king\"),\n",
    "     ContextWord(\"queen does not do such things\", \"queen\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40263602"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"I captured the opponent's king.\", \"king\"),\n",
    "     ContextWord(\"I captured the opponent's queen.\", \"queen\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21260612"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"king, please forgive me!\", \"king\"),\n",
    "     ContextWord(\"queen, please forgive me!\", \"queen\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44601032"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"his attitude is irritating.\", \"his\"), \n",
    "     ContextWord(\"her attitude is irritating.\", \"her\")),\n",
    "    (ContextWord(\"they are the king.\", \"king\"),\n",
    "     ContextWord(\"they are the queen.\", \"queen\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
